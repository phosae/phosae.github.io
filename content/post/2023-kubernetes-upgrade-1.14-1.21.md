---
title: "v1.14.5 - v1.21.14 Kubernetes è·¨ç‰ˆæœ¬å‡çº§è®°å½•"
date: 2023-11-30T16:58:24+08:00
lastmod: 2024-05-24T16:38:00+08:00
draft: false
keywords: ["kubernetes"]
description: "Upgrade Kubernetes from v1.14.5 to v1.21.14"
tags: ["kubernetes"]
author: "Zeng Xu"
summary: "v1.14.5 - v1.21.14 Kubernetes è·¨ç‰ˆæœ¬å‡çº§è®°å½•"

comment: true
toc: true
autoCollapseToc: false
postMetaInFooter: true
hiddenFromHomePage: false
contentCopyright:  'æœ¬ä½œå“é‡‡ç”¨ <a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç¦æ­¢æ¼”ç» 4.0 å›½é™…è®¸å¯åè®®</a> è¿›è¡Œè®¸å¯ï¼Œè½¬è½½æ—¶è¯·æ³¨æ˜åŸæ–‡é“¾æ¥ã€‚'    
reward: false
mathjax: false
mathjaxEnableSingleDollar: false
mathjaxEnableAutoNumber: false

# You unlisted posts you might want not want the header or footer to show
hideHeaderAndFooter: false
---

## èƒŒæ™¯å’Œå‡çº§ç­–ç•¥

å‡çº§é›†ç¾¤ï¼Œé¦–å…ˆå…³æ³¨å“ªäº› API åœ¨æ–°ç‰ˆæœ¬è¢«åºŸå¼ƒ (ç§»é™¤) äº†ã€‚è¿™ä¸€ç‚¹å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ [Deprecated API Migration Guide]ã€‚
å°½ç®¡ K8s æœ€æ–°ç‰ˆæœ¬å·²ç»æ˜¯ v1.28.4ï¼Œä½†æˆ‘ä»¬çº¿ä¸Š K8s ç‰ˆæœ¬ä»æ—§ä¸º v1.14.5ã€‚ç”±äºä¸šåŠ¡ä¾èµ–çš„ä¸å°‘ API åœ¨ 1.22 ä¹‹åè¢«ç§»é™¤ï¼Œå¦‚
- admissionregistration.k8s.io/v1beta1 MutatingWebhookConfiguration and ValidatingWebhookConfiguration
- apiextensions.k8s.io/v1beta1 CustomResourceDefinition
- coordination.k8s.io/v1beta1 Lease
- extensions/v1beta1 Ingress, networking.k8s.io/v1beta1 Ingress
- networking.k8s.io/v1beta1 IngressClass

è¿™ä¾¿å†³å®šäº†æ— æ³•ä¸€æ­¥åˆ°ä½å‡åˆ° v1.28.xï¼Œè€Œåªèƒ½é‡‡ç”¨å…ˆå‡çº§åˆ° v1.21.x å†é€æ­¥å¾€ä¸Šå‡çº§çš„æ–¹å¼ã€‚æœ¬æ–‡è®°å½• v1.14.5 åˆ° v1.21.14 çš„æ“ä½œæ­¥éª¤å’Œé—®é¢˜è§£å†³æ–¹å¼ã€‚

é›†ç¾¤å‡çº§æ–¹å¼ä¸€èˆ¬æœ‰ä¸¤ç§ï¼Œå…¶ä¸€æ˜¯å¦å»ºç›®æ ‡é›†ç¾¤å¹¶é€æ­¥è¿ç§»å®Œæ‰€æœ‰æœåŠ¡ï¼Œå…¶äºŒæ˜¯é€èŠ‚ç‚¹åŸåœ°å‡çº§ã€‚
å¦‚æœé€‰æ‹©å¦å»º v1.21.x å¹¶æ‰§è¡Œè¿ç§»çš„æ–¹å¼ï¼Œå…ˆè¦åœ¨å¤–å±‚ç½‘å…³å±‚å®ç°é›†ç¾¤åˆ‡æµåŠŸèƒ½ï¼Œå†è¦æå‰åœ¨æ–°é›†ç¾¤éƒ¨ç½²å¥½æ‰€æœ‰æœåŠ¡ï¼Œæœ€ç»ˆé€æ­¥å®Œæˆåˆ‡æµã€‚
è€ƒè™‘åˆ°æˆ‘ä»¬æ²¡æœ‰ä¸»ä»é›†ç¾¤åˆ‡æµå±‚ã€æœºå™¨èµ„æºç›¸å¯¹æœ‰é™ã€åŠ ä¹‹é›†ç¾¤æœ‰çŠ¶æ€æœåŠ¡æ²¡æ³•ç®€å•æŒªç§»ï¼Œå› æ­¤é€‰æ‹©äº†åŸåœ°å‡çº§ã€‚

kubeadm åœ¨ v1.29 ä¹‹å‰ä»…æ”¯æŒé€ minor ç‰ˆæœ¬å‡çº§é›†ç¾¤ï¼Œå³åªèƒ½ v1.14 -> v1.15 -> v1.16 -> v1.17 -> v1.18 -> v1.19 -> v1.20 -> v1.21ã€‚è¯¦ç»†å¯å‚è€ƒ [Upgrading kubeadm clusters]ã€‚ï¼ˆkubeadm v1.29 ä¹‹åå°†æ”¯æŒè·¨ 3 ä¸ª minor ç‰ˆæœ¬å‡çº§ï¼Œå³å¯ä»¥ v1.26 -> v1.29 -> v1.32ï¼Œè¯¦ç»†å¯å‚è€ƒ [kubeadm#2924 - adjust the kubeadm/kubelet skew policy] ğŸš€

åˆï¼Œä» v1.14 è‡³ v1.21ï¼Œkubelet ä¸ apiserver ä¹‹é—´çš„é€šä¿¡ API æ²¡æœ‰å‘ç”Ÿç§»é™¤ï¼Œv1.14 kubelet å¯ä¸ v1.14.5 åˆ° v1.21.14 ä¹‹é—´çš„ä»»ä½•ç‰ˆæœ¬çš„ apiserver é€šä¿¡ã€‚
å› æ­¤å‡çº§ç­–ç•¥ä¸º
1. é€æ­¥å‡çº§ control plane è‡³ v1.21
2. ä¸€æ­¥åˆ°ä½å‡çº§ worker node v1.14 è‡³ v1.21

<img src="/img/2023/k8s-upgrade-flow.png" width="600px"/>

è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå³ä½¿å‡çº§ kubelet æ—¶ Pod Containers æœ‰è¢«é‡å¯çš„é£é™©ã€‚è¿™äº‹ä¹Ÿåªä¼šå‘ç”Ÿä¸€æ¬¡ã€‚æ³¨æ„
- å‡çº§ kubelet å¯èƒ½å¯¼è‡´ Pod Containers è¢«é‡å¯ï¼Œè§ [kubernetes#63814 - kubelet's calculation of whether a container has changed can cause cluster-wide outages]
- ç”šè‡³å‡çº§ containerd ä¹Ÿå¯èƒ½å¯¼è‡´é‡å¯ [containerd#7845 - CRI: Fix no CNI info for pod sandbox on restart]

é€šå¸¸æ¥è¯´ï¼Œå¥å£®çš„æœåŠ¡ç¾¤åº”èƒ½å®¹å¿å¶å‘é‡å¯æˆ–è€…é‡æ–°è°ƒåº¦ã€‚

## cluster çº§å‡çº§ï¼ˆåœ¨é¦–ä¸ª master èŠ‚ç‚¹æ‰§è¡Œ

```bash
{
# download kubeadm, kubelet, kubectl binary
for VERSION in v1.15.12 v1.16.15 v1.17.17 v1.18.20 v1.19.16 v1.20.15 v1.21.14; do
  wget -O /etc/kubernetes/upgrade/kubeadm-$VERSION https://storage.googleapis.com/kubernetes-release/release/$VERSION/bin/linux/amd64/kubeadm
  chmod +x /etc/kubernetes/upgrade/kubeadm-$VERSION
  wget -O /etc/kubernetes/upgrade/kubelet-$VERSION https://storage.googleapis.com/kubernetes-release/release/$VERSION/bin/linux/amd64/kubelet
  chmod +x /etc/kubernetes/upgrade/kubelet-$VERSION
  wget -O kubectl-$VERSION https://storage.googleapis.com/kubernetes-release/release/$VERSION/bin/linux/amd64/kubectl
  chmod +x /etc/kubernetes/upgrade/kubectl-$VERSION
done

# start copying container images to the private registry:  
#   kube-apiserver, kube-controller-manager, kube-scheduler, kube-proxy, coredns, pause
# if your company has no private registry, you can skip this step
for VERSION in v1.15.12 v1.16.15 v1.17.17 v1.18.20 v1.19.16 v1.20.15 v1.21.14; do
  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/kube-apiserver:$VERSION docker://myregisty/google-containers/kube-apiserver:$VERSION
  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/kube-controller-manager:$VERSION docker://myregisty/google-containers/kube-controller-manager:$VERSION
  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/kube-scheduler:$VERSION docker://myregisty/google-containers/kube-scheduler:$VERSION
  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/kube-proxy:$VERSION docker://myregisty/google-containers/kube-proxy:$VERSION
done
for VERSION in 1.6.2 1.6.5 1.6.7 1.7.0 v1.8.0; do
  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/coredns:$VERSION docker://myregistry/google-containers/coredns:$VERSION
done
for VERSION in 3.2 3.4.1; do
  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/pause:$VERSION docker://myregistry/google-containers/pause:$VERSION
done
# end copying container images
}
```

ä½¿ç”¨ `kubeadm upgrade apply <targetVersion>` æ‰§è¡Œé¦–ä¸ª control plane å‡çº§ã€‚

```bash
# control plane ä¸º v1.14.5ï¼Œwoker nodes ä¸º v1.14.5ï¼Œæ­£å¸¸ä½¿ç”¨ kubeadm upgrade apply å³å¯
/etc/kubernetes/upgrade/kubeadm-v1.15.12 upgrade apply v1.15.12
# control plane ä¸º v1.15.12ï¼Œwoker nodes ä¸º v1.14.5ï¼Œå¿…é¡»æ­é… -f å‚æ•°å¼ºåˆ¶å‡çº§
/etc/kubernetes/upgrade/kubeadm-v1.16.15 upgrade apply v1.16.15 -f
# control plane ä¸º v1.16.15ï¼Œwoker nodes ä¸º v1.14.5ï¼Œå¿…é¡»æ­é… -f å‚æ•°å¼ºåˆ¶å‡çº§
/etc/kubernetes/upgrade/kubeadm-v1.17.17 upgrade apply v1.17.17 -f 
# control plane ä¸º v1.17.17ï¼Œwoker nodes ä¸º v1.14.5ï¼Œå¿…é¡»æ­é… -f å‚æ•°å¼ºåˆ¶å‡çº§
/etc/kubernetes/upgrade/kubeadm-v1.18.20 upgrade apply v1.18.20 -f
# control plane ä¸º v1.18.20ï¼Œwoker nodes ä¸º v1.14.5ï¼Œå¿…é¡»æ­é… -f å‚æ•°å¼ºåˆ¶å‡çº§
/etc/kubernetes/upgrade/kubeadm-v1.19.16 upgrade apply v1.19.16 -f
# control plane ä¸º v1.19.16ï¼Œwoker nodes ä¸º v1.14.5ï¼Œå¿…é¡»æ­é… -f å‚æ•°å¼ºåˆ¶å‡çº§
/etc/kubernetes/upgrade/kubeadm-v1.20.15 upgrade apply v1.20.15 -f
# control plane ä¸º v1.20.15ï¼Œwoker nodes ä¸º v1.14.5ï¼Œå¿…é¡»æ­é… -f å‚æ•°å¼ºåˆ¶å‡çº§
/etc/kubernetes/upgrade/kubeadm-v1.21.14 upgrade apply v1.21.14 -f
```

æ¯æ¬¡æ‰§è¡Œä¹‹åï¼Œå¤§è‡´å‘ç”Ÿä»¥ä¸‹äº‹æƒ…
- apply kube-system ä¸­çš„é›†ç¾¤é…ç½®ï¼Œå¦‚ kubeadm-config (i.e ClusterConfiguration)ï¼Œkubelet-config-$VERSIONï¼ŒCoreDNS ä»¥åŠ kube-proxy ConfigMap
- æ›´æ–°é¦–ä¸ª master èŠ‚ç‚¹ä¸Šçš„ kube-apiserver, kube-controller-manager, kube-schedulerï¼ˆå³ /etc/kubernetes/manifests ç›®å½•çš„ static Pod manifests
- æ›´æ–°é›†ç¾¤ä¸­çš„ CoreDNS å’Œ kube-proxy

æ‰€ä»¥æ¯æ¬¡æ›´æ–°å®Œé›†ç¾¤ä¹‹åï¼Œéœ€è¦æ£€æŸ¥ä»¥ä¸‹æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ
- é¦–ä¸ª master èŠ‚ç‚¹ä¸Šçš„ kube-apiserver, kube-controller-manager, kube-scheduler
- CoreDNS
- kube-proxy
- CNI Plugin

## å…¶ä»– master èŠ‚ç‚¹æ›´æ–°

ä¸‹è½½ç¨‹åº

```bash
{
for VERSION in v1.15.12 v1.16.15 v1.17.17 v1.18.20 v1.19.16 v1.20.15 v1.21.14; do
  wget -O /etc/kubernetes/upgrade/kubeadm-$VERSION https://storage.googleapis.com/kubernetes-release/release/$VERSION/bin/linux/amd64/kubeadm
  chmod +x /etc/kubernetes/upgrade/kubeadm-$VERSION
  wget -O /etc/kubernetes/upgrade/kubelet-$VERSION https://storage.googleapis.com/kubernetes-release/release/$VERSION/bin/linux/amd64/kubelet
  chmod +x /etc/kubernetes/upgrade/kubelet-$VERSION
  wget -O kubectl-$VERSION https://storage.googleapis.com/kubernetes-release/release/$VERSION/bin/linux/amd64/kubectl
  chmod +x /etc/kubernetes/upgrade/kubectl-$VERSION
done
}
```

æ‰§è¡Œ `kubeadm upgrade node` å³å¯

```bash
{ 
VERSION=v1.15.12 # v1.16.15 ... v1.21.14 ç­‰å…¶ä»–ç‰ˆæœ¬å¯¹å·å…¥åº§
./kubeadm-$VERSION upgrade node --certificate-renewal=false
mv kubelet-$VERSION /usr/local/bin/kubelet
sudo systemctl daemon-reload
sudo systemctl restart kubelet
}
```

å¯¹äº control plane æ‰€åœ¨èŠ‚ç‚¹ï¼Œæ‰§è¡Œ `kubeadm upgrade node` ä¼š
- è·å– kubeadm `ClusterConfiguration`ï¼Œæ›´æ–° kube-apiserver, kube-controller-manager, kube-scheduler ï¼ˆå³ static Pod manifests
- æ›´æ–° kubelet å¯åŠ¨é…ç½®

å› æ­¤ä¹‹ååªè¦æ›´æ¢ kubelet äºŒè¿›åˆ¶ï¼Œé‡å¯ kubelet å³å¯å®Œæˆ control plane èŠ‚ç‚¹æ›´æ–°ã€‚

## 1.14 â†’ 1.15 è¸©å‘è®°å½•

- kubelet æ— æ³•å¯åŠ¨ï¼ŒåŸå› æ˜¯ [kubernetes#77820 - Remove deprecated Kubelet security controls] ç§»é™¤äº†è¯¥å‚æ•°

    ```
    Nov 28 18:05:27 master-1 kubelet[884]: F1128 18:05:27.064279     884 server.go:156] unknown flag: --allow-privileged
    ```
    è§£å†³æ–¹å¼ï¼Œåœ¨ /etc/kubernetes/kubelet.env ç§»é™¤ `KUBE_ALLOW_PRIV="--allow-privileged=true"` å¹¶åœ¨  /etc/systemd/system/kubelet.service ç§»é™¤ `$KUBE_ALLOW_PRIV` ç¯å¢ƒå˜é‡å¼•ç”¨ã€‚
- coredns deployments æ–° Pod æ— æ³•è¢«åˆ›å»ºï¼ŒåŸå› æ˜¯ kube-system ä¸­æœ‰è«åå…¶å¦™çš„ LimitRange èµ„æºï¼Œé™åˆ¶äº†å®¹å™¨æœ€å°èµ„æºè¯·æ±‚æœ€å° CPU ä¸º 100mï¼Œæœ€å° Memory ä¸º 100Miã€‚è§£å†³æ–¹å¼ï¼Œåˆ é™¤ LimitRange å³å¯ã€‚
- è‡ªç ” AutoScaler ç»„ä»¶å¤±æ•ˆï¼Œä½¿ç”¨ label container_name çªç„¶å–ä¸åˆ° CPU Metrics æ•°æ®ã€‚åŸå› æ˜¯ 1.15 å [kubernetes#76074 - change kubelet probe metrics to counter] ç§»é™¤äº† CPU Metrics label container_nameã€‚è§£å†³æ–¹å¼æ˜¯ä¿®æ”¹ Metrics æŸ¥è¯¢ä¸º label containerã€‚å¦‚æœä½¿ç”¨äº† label pod_nameï¼Œä¹Ÿåº”è¯¥ä¿®æ”¹ä¸º label podã€‚

## 1.15 -> 1.16 è¸©å‘è®°å½•

æ›´æ–°é•œåƒåˆ° `coredns:1.6.2` ä¹‹åï¼ŒCoreDNS Deployment ä¸‹çš„ Pod æ­£å¸¸ Running ä½†ä¸€ç›´æœª Readyã€‚

```bash
root@master-0:/etc/kubernetes/upgrade# kubectl -n kube-system get po | grep core
coredns-8656b5f45f-gvbqd                  1/1     Running   1          20h
coredns-ddd4d886f-4nwd5                   0/1     Running   0          24m
coredns-ddd4d886f-nk9mp                   0/1     Running   0          24m
```
åŸå› æ˜¯ coreDNS 1.6 ä¹‹å readiness serve æ”¹ä¸ºäº†æ’ä»¶æ¨¡å¼ï¼Œè¯¦è§ [coredns#3219 - Readiness probe failed 8181: connect: connection refused]

è§£å†³æ–¹å¼ï¼š`kubectl -n kube-system edit cm coredns` æ¿€æ´» ready æ’ä»¶ 

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors
        health {
            lameduck 5s
        }
        kubernetes lac-k8s-prd.local in-addr.arpa ip6.arpa {
            pods insecure
            fallthrough in-addr.arpa ip6.arpa
        }
        prometheus :9153
        ready :8181 # å¢åŠ è¿™ä¸€è¡Œ
        forward . /etc/resolv.conf {
            max_concurrent 1000
        }
        cache 30
        loop
        reload
        loadbalance
    }
```

## 1.18 -> 1.19 è¸©å‘è®°å½•

- feature gate `VolumeSubpathEnvExpansion` åœ¨ 1.19 è¢«ç§»é™¤ï¼Œå¯¼è‡´æ‰§è¡Œ `kubeadm upgrade` åï¼Œkube-apiserver, kube-controller-manager, kube-scheduler, kube-proxy, kubelet å‡æ— æ³•å¯åŠ¨ã€‚è§£å†³æ–¹å¼
  1. æå‰è‡ª kubeadm ClusterConfiguration ä¸­ç§»é™¤ `feature-gates: VolumeSubpathEnvExpansion=true`ã€‚ä¸€èˆ¬æ˜¯ç½®ç©º `- --feature-gates=`ã€‚
  2. æå‰è‡ª kube-proxy ConfigMap ç§»é™¤ `feature-gates: VolumeSubpathEnvExpansion=true`ã€‚
  3. æå‰è‡ª /etc/kubernetes/kubelet.env ç§»é™¤ `feature-gates: VolumeSubpathEnvExpansion=true`ã€‚ï¼ˆ`sed -i '/--feature-gates=VolumeSubpathEnvExpansion=true \\/d'  /etc/kubernetes/kubelet.env`
- è§¦å‘ Prometheus å‘Šè­¦: ğŸ˜±ğŸš€ KubeScheduler/KubeControllerManager has disappeared from Prometheus target discoveryã€‚
    åŸå› æ˜¯ Prometheus ä½¿ç”¨ HTTP EndPoints <host>:10251/ready æ¢æµ‹ KubeScheduler æ˜¯å¦å°±ç»ªï¼Œä½†åœ¨ 1.19 ç§»é™¤äº†è¿™ä¸€é»˜è®¤ç«¯å£ã€‚
    è¯¦è§ [kubeadm#2207 - remove --port from kube-controller-manager and kube-scheduler]
    ```
    up{endpoint="http-metrics",instance="10.40.34.34:10251",job="kube-scheduler",namespace="kube-system",pod="kube-scheduler-master0",service="basic-kube-scheduler"} 
    0
    ```
    è§£å†³æ–¹å¼ï¼Œè‡ªå·± kube-scheduler å’Œ kube-controller-manager manifest åˆ é™¤å¯åŠ¨å‚æ•° `- --port=0`ï¼ˆ`sed -i '/- --port=0/d'  /etc/kubernetes/manifests/kube-scheduler.yaml  /etc/kubernetes/manifests/kube-controller-manager.yaml`
- éƒ¨åˆ† Webhook è¯ä¹¦çªç„¶å¤±æ•ˆ
    ```
    2023-11-30T14:46:44.577+0800    ERROR ... 
    err: Internal error occurred: 
    failed calling webhook \"mutate-deploy.x.com\": 
      Post \"https://x.kube-system.svc:443/mutate-deployment?timeout=30s\": 
        x509: certificate relies on legacy Common Name field, 
          use SANs or temporarily enable Common Name matching with GODEBUG=x509ignoreCN=0"
    ```
    è§£å†³æ–¹å¼ï¼Œæ›´æ–° kube-apiserver manifestsï¼Œç»™ Pod å¢åŠ ç¯å¢ƒå˜é‡å³å¯
    ```
    env:
    - name: GODEBUG
    value: "x509ignoreCN=0"
    ```
    è¯¥æ–¹å¼åœ¨ 1.23 å‰æœ‰æ•ˆï¼Œè¯¦è§ [GKE: Ensuring compatibility of webhook certificates before upgrading to v1.23]

## 1.19 -> 1.20 æ³¨æ„ç‚¹
- kubelet ä¼šä½¿ç”¨ pause:3.2ï¼Œéœ€è¦ä¿è¯ pause:3.2 åœ¨å†…ç½‘å¯æ‹‰å–
- v1.19 è‡³ v1.20 æœ€å¤§å˜åŒ–å°±æ˜¯åºŸå¼ƒäº† `apiserver serve on an insecure port`ï¼Œå› æ­¤åœ¨å‡çº§å‰åº”è¯¥ä¿®æ”¹ kubeadm ClusterConfiguration ç§»é™¤ apiserver å‚æ•° `--insecure-bind-address` å’Œå‚æ•° `--insecure-port`ã€‚åŒæ—¶åº”è¯¥æ£€æŸ¥å·¦å³å®¢æˆ·ç«¯ kubeconfigï¼Œå¦‚æœä½¿ç”¨äº† HTTP è¿æ¥ kube-apiserverï¼Œåº”è¯¥æ›´æ–°è‡³ HTTPS ç‰ˆã€‚
- ä¸ºå…¼å®¹ Prometheus HTTP æ¢æµ‹ kube-scheduler å’Œ kube-controller-managerï¼Œåº”è¯¥ç»§ç»­æ‰§è¡Œ `sed -i '/- --port=0/d'  /etc/kubernetes/manifests/kube-scheduler.yaml  /etc/kubernetes/manifests/kube-controller-manager.yaml`
- 1.20 kubelet ç§»é™¤äº† endpoint `metrics/resource/v1alpha1`ï¼Œå¦‚æœ Prometheus é…ç½®äº†ä»è¯¥è·¯å¾„çˆ¬å– Metrics çš„ ServiceMonitorï¼Œéœ€ä¿®æ”¹å¯¹åº”èµ„æºï¼Œæ”¹æˆ `metrics/resource`

## 1.20 -> 1.21 æ³¨æ„ç‚¹
- kubelet ä¼šä½¿ç”¨ pause:3.4.1ï¼Œéœ€è¦ä¿è¯ pause:3.4.1 åœ¨å†…ç½‘å¯æ‹‰å–
- ä¸ºå…¼å®¹ Prometheus HTTP æ¢æµ‹ kube-scheduler å’Œ kube-controller-managerï¼Œåº”è¯¥ç»§ç»­æ‰§è¡Œ `sed -i '/- --port=0/d'  /etc/kubernetes/manifests/kube-scheduler.yaml  /etc/kubernetes/manifests/kube-controller-manager.yaml`
- 1.21 feature BoundServiceAccountTokenVolume é»˜è®¤å¯ç”¨åï¼ŒServiceAccount å‡­è¯ä» Secret æŒ‚è½½æ”¹ä¸ºåŠ¨æ€ Token è·å–ã€‚æŒ‰ç…§å£°æ˜æ¥çœ‹æŒ‚è½½æƒé™æ— å·®å¼‚ã€‚ä½†åœ¨ç”Ÿäº§é›†ç¾¤ä¸­ï¼ŒPod Container è®¾ç½® `securityContext.runAsUser: 101` ä»¥é root user è¿è¡Œæ—¶ï¼Œè¯»å– token æ–‡ä»¶æŠ¥é”™ `open /var/run/secrets/kubernetes.io/serviceaccount/token: permission denied` (container image: quay.io/kubernetes-ingress-controller/[nginx-ingress-controller:0.31.0])ã€‚
    ```
    # before 1.21
    - name: nginx-ingress-serviceaccount-token-vqxzw
      secret:
        defaultMode: 420
        secretName: nginx-ingress-serviceaccount-token-vqxzw
    ---
    # after 1.21
    volumes:
    - name: kube-api-access-xbwws
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
    ```
    è§£å†³æ–¹å¼ï¼šä¸º Pod è®¾ç½® `spec.securityContext.fsGroup: 65534`ï¼Œç¡®ä¿æ‰€æœ‰ container å¯¹æŒ‚è½½ç›®å½•æœ‰è¯»å–æƒé™ã€‚

## ç³»ç»Ÿçº§é•œåƒå‘ç‚¹

å¦‚å› å†…ç½‘ç¯å¢ƒæˆ–è€…å…¶ä»–åŸå› å¯¼è‡´å›½å¤–é•œåƒä¸å¯è¾¾ï¼Œåº”è¯¥ä½¿ç”¨ `kubeadm apply <targetVersion> --dry-run` æ‰“å°æ‰§è¡Œç»“æœï¼Œé‡ç‚¹ grep å¦‚ä¸‹ç»„ä»¶é•œåƒå¹¶æå‰åšå¥½åˆ†å‘
- CoreDNS
- pause

å°èŠ‚ cluster çº§å‡çº§å¼€å¤´çš„é•œåƒåˆ†å‘æ˜¯èµ°å®Œæ•´ä¸ªæµç¨‹çš„æˆæœã€‚

## ä»»æ„ worker èŠ‚ç‚¹æ›´æ–°

èµ°å®Œ control plane èŠ‚ç‚¹æ›´æ–°ï¼Œä¹Ÿå°±è¸©å®Œäº†æ™®é€š worker èŠ‚ç‚¹çš„å‘ã€‚è„šåŒ–å¤„ç†å³å¯ã€‚æ‰¾ä¸€å°å¯ä»¥ç™»é™†æ‰€æœ‰ worker çš„æœºå™¨ï¼Œå‡†å¤‡è„šæœ¬ `upgrade-worker.sh`

```bash
#!/bin/bash
VERSION=v1.21.14
UPGRADEDIR=/etc/kubernetes/upgrade
mkdir -p $UPGRADEDIR

wget -O $UPGRADEDIR/kubeadm-$VERSION https://storage.googleapis.com/kubernetes-release/release/$VERSION/bin/linux/amd64/kubeadm
chmod +x $UPGRADEDIR/kubeadm-$VERSION
wget -O $UPGRADEDIR/kubelet-$VERSION https://storage.googleapis.com/kubernetes-release/release/$VERSION/bin/linux/amd64/kubelet
chmod +x $UPGRADEDIR/kubelet-$VERSION

# start of updating args, it depends on your kubelet's status, don't use it
sed -i '/# Should this cluster be allowed to run privileged docker containers/d; /KUBE_ALLOW_PRIV="--allow-privileged=true"/d' /etc/kubernetes/kubelet.env
sed -i '/\$KUBE_ALLOW_PRIV \\/d' /etc/systemd/system/kubelet.service
sed -i '/--feature-gates=VolumeSubpathEnvExpansion=true \\/d'  /etc/kubernetes/kubelet.env
sed -i 's|google-containers/pause-amd64:3.1|google-containers/pause:3.4.1|' /etc/kubernetes/kubelet.env
# end of updating args, it depends on your kubelet's status, don't use it

$UPGRADEDIR/kubeadm-$VERSION upgrade node
mv $UPGRADEDIR/kubelet-$VERSION /usr/local/bin/kubelet
systemctl daemon-reload
systemctl restart kubelet
```

ç„¶åæŒ‰ç…§å®é™…ä¸šåŠ¡æƒ…å†µï¼Œåˆ†æ‰¹æ¬¡å®Œæˆ kubelet v1.14 è‡³ v1.21 å‡çº§ã€‚

```bash
for NODE in work-1 work-2 work-3; do
    kubectl drain $NODE --ignore-daemonsets --delete-local-data
    ssh $NODE "bash -s" -- < /etc/kubernetes/upgrade/upgrade-worker.sh
    kubectl uncordon $NODE
done
```

æ³¨æ„: kubelet æ›´æ–°æ—¶æ‰€æ¶‰åŠçš„å‚æ•°æ›´æ–°ï¼Œå¦‚ `å‚æ•°ç§»é™¤`ï¼Œ `feature-gates ç§»é™¤`ï¼Œ `pause container æ›´æ–°` ç­‰ï¼Œå…·ä½“å› å®é™…é›†ç¾¤è€Œå¼‚ã€‚

## æ€»ç»“
é›†ç¾¤å‡çº§æ¦‚è¦
1. å…ˆæµ‹è¯•é›†ç¾¤åç”Ÿäº§é›†ç¾¤ï¼Œå…ˆå°é›†ç¾¤åå¤§é›†ç¾¤ 
2. æå‰å¤‡ä»½ etcdï¼Œè™½ç„¶æœ¬æ–‡æ²¡ç”¨ä¸Šå¤‡ä»½ ğŸ‘»
3. æŸ¥é˜… [Kubernetes CHANGELOG]ï¼Œæ³¨æ„æ–°ç‰ˆæœ¬æ ¸å¿ƒç»„ä»¶çš„å‚æ•°ç§»é™¤ï¼Œå°¤å…¶æ˜¯ feature gates ç§»é™¤ä¼šæ¶‰åŠæ‰€æœ‰ `kube-` æ‰“å¤´ç»„ä»¶
4. æå‰ `kubeadm upgrade <version> --dryrun` æ£€æŸ¥æ–°ç‰ˆæœ¬é•œåƒï¼Œåšå¥½ CoreDNS å’Œ puase å®¹å™¨é•œåƒåˆ†å‘
5. upgrade å®Œæˆåï¼Œæ£€æŸ¥ CoreDNS å’Œ kube-proxy æ‰€æœ‰ Pod çŠ¶æ€ï¼Œç¡®ä¿æ›´æ–°å®Œæˆï¼›æ£€æŸ¥é›†ç¾¤ DNS åŠŸèƒ½æ˜¯å¦æ­£å¸¸ï¼›æ£€æŸ¥é›†ç¾¤ Service åŠŸèƒ½æ˜¯å¦æ­£å¸¸
6. æ¯æ¬¡ upgrade å®Œæˆï¼Œæ£€æŸ¥ Operator/Controller å’Œå…³é”®ä¸šåŠ¡åº”ç”¨æ˜¯å¦æ­£å¸¸ï¼ˆå…³æ³¨æ—¥å¿—/ç›‘æ§/å‘Šè­¦ï¼‰ï¼Œæ£€æŸ¥æ ¸å¿ƒ API CRUD æ˜¯å¦æ­£å¸¸ï¼ˆé˜²æ­¢ Webhook å´©åï¼‰

 Container Runtime æ›´æ–°éƒ¨åˆ†ã€æœ€ç»ˆæ“ä½œæ–¹å¼å’Œè„šæœ¬è¯·æŸ¥é˜… [Kubernetes v1.14.5 â†’ v1.21.14 å‡çº§è¡¥é—åŠç»éªŒæ•™è®­]ã€‚

## å‚è€ƒé“¾æ¥
- TauCeti.blog's Kubernetes upgrade notes: [1.14-1.15](https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.14-1.15/), [1.15-1.16](https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.15-1.16/), [1.16-1.17](https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.16-1.17/), [1.17-1.18](https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.17-1.18/), [1.18-1.19](https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.17-1.18/), [1.19-1.20](https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.17-1.18/), [1.20-1.21](https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.20-1.21/)
- [Deprecated API Migration Guide]
- [Upgrading kubeadm clusters]
- [Kubernetes CHANGELOG]

[Deprecated API Migration Guide]: https://kubernetes.io/docs/reference/using-api/deprecation-guide
[Upgrading kubeadm clusters]: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/
[Kubernetes CHANGELOG]: https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG

[containerd#7845 - CRI: Fix no CNI info for pod sandbox on restart]: https://github.com/containerd/containerd/pull/7845
[kubernetes#63814 - kubelet's calculation of whether a container has changed can cause cluster-wide outages]: https://github.com/kubernetes/kubernetes/issues/63814
[kubernetes#76074 - change kubelet probe metrics to counter]: https://github.com/kubernetes/kubernetes/pull/76074
[kubernetes#77820 - Remove deprecated Kubelet security controls]: https://github.com/kubernetes/kubernetes/pull/77820
[coredns#3219 - Readiness probe failed 8181: connect: connection refused ]: https://github.com/coredns/coredns/issues/3219
[GKE: Ensuring compatibility of webhook certificates before upgrading to v1.23]: https://cloud.google.com/kubernetes-engine/docs/deprecations/webhookcompatibility
[kubeadm#2207 - remove --port from kube-controller-manager and kube-scheduler]: https://github.com/kubernetes/kubeadm/issues/2207
[kubeadm#2924 - adjust the kubeadm/kubelet skew policy]: https://github.com/kubernetes/kubeadm/issues/2924
[Kubernetes v1.14.5 â†’ v1.21.14 å‡çº§è¡¥é—åŠç»éªŒæ•™è®­]: ../2024-kubernetes-upgrade-lessons
[nginx-ingress-controller:0.31.0]: https://github.com/kubernetes/ingress-nginx/tree/controller-0.31.0