<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>v1.14.5 - v1.21.14 Kubernetes 跨版本升级记录 - ZengXu&#39;s BLOG</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Zeng Xu" /><meta name="description" content="Upgrade Kubernetes from v1.14.5 to v1.21.14" /><meta name="keywords" content="kubernetes" />






<meta name="generator" content="Hugo 0.125.0 with theme even" />


<link rel="canonical" href="https://www.zeng.dev/post/2023-kubernetes-upgrade-1.14-1.21/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.3ab191e0444a0833d62fa8f1e44231fc793f2c04a2474a8b9348894c550f8388.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://www.zeng.dev/post/2023-kubernetes-upgrade-1.14-1.21/">
  <meta property="og:site_name" content="ZengXu&#39;s BLOG">
  <meta property="og:title" content="v1.14.5 - v1.21.14 Kubernetes 跨版本升级记录">
  <meta property="og:description" content="Upgrade Kubernetes from v1.14.5 to v1.21.14">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
  <meta property="article:section" content="post">
    <meta property="article:published_time" content="2023-11-30T16:58:24+08:00">
    <meta property="article:modified_time" content="2024-05-24T16:38:00+08:00">
    <meta property="article:tag" content="Kubernetes">

  <meta itemprop="name" content="v1.14.5 - v1.21.14 Kubernetes 跨版本升级记录">
  <meta itemprop="description" content="Upgrade Kubernetes from v1.14.5 to v1.21.14">
  <meta itemprop="datePublished" content="2023-11-30T16:58:24+08:00">
  <meta itemprop="dateModified" content="2024-05-24T16:38:00+08:00">
  <meta itemprop="wordCount" content="3555">
  <meta itemprop="keywords" content="kubernetes"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="v1.14.5 - v1.21.14 Kubernetes 跨版本升级记录">
<meta name="twitter:description" content="Upgrade Kubernetes from v1.14.5 to v1.21.14">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Zeng Xu&#39;s BLOG</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="https://www.notion.so/zengxu/Zeng-Xu-s-Little-World-a6b002fb4d134333abe74a4e0491cea7">
        <li class="mobile-menu-item">杂文</li>
      </a><a href="/about">
        <li class="mobile-menu-item">我</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Zeng Xu&#39;s BLOG</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.notion.so/zengxu/Zeng-Xu-s-Little-World-a6b002fb4d134333abe74a4e0491cea7">杂文</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about">我</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">v1.14.5 - v1.21.14 Kubernetes 跨版本升级记录</h1>

      <div class="post-meta">
        <span class="post-time"> 2023-11-30 16:58 </span>
        
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#背景和升级策略">背景和升级策略</a></li>
    <li><a href="#cluster-级升级在首个-master-节点执行">cluster 级升级（在首个 master 节点执行</a></li>
    <li><a href="#其他-master-节点更新">其他 master 节点更新</a></li>
    <li><a href="#114--115-踩坑记录">1.14 → 1.15 踩坑记录</a></li>
    <li><a href="#115---116-踩坑记录">1.15 -&gt; 1.16 踩坑记录</a></li>
    <li><a href="#118---119-踩坑记录">1.18 -&gt; 1.19 踩坑记录</a></li>
    <li><a href="#119---120-注意点">1.19 -&gt; 1.20 注意点</a></li>
    <li><a href="#120---121-注意点">1.20 -&gt; 1.21 注意点</a></li>
    <li><a href="#系统级镜像坑点">系统级镜像坑点</a></li>
    <li><a href="#任意-worker-节点更新">任意 worker 节点更新</a></li>
    <li><a href="#总结">总结</a></li>
    <li><a href="#参考链接">参考链接</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h2 id="背景和升级策略">背景和升级策略</h2>
<p>升级集群，首先关注哪些 API 在新版本被废弃 (移除) 了。这一点可以参考官方文档 <a href="https://kubernetes.io/docs/reference/using-api/deprecation-guide">Deprecated API Migration Guide</a>。
尽管 K8s 最新版本已经是 v1.28.4，但我们线上 K8s 版本仍旧为 v1.14.5。由于业务依赖的不少 API 在 1.22 之后被移除，如</p>
<ul>
<li>admissionregistration.k8s.io/v1beta1 MutatingWebhookConfiguration and ValidatingWebhookConfiguration</li>
<li>apiextensions.k8s.io/v1beta1 CustomResourceDefinition</li>
<li>coordination.k8s.io/v1beta1 Lease</li>
<li>extensions/v1beta1 Ingress, networking.k8s.io/v1beta1 Ingress</li>
<li>networking.k8s.io/v1beta1 IngressClass</li>
</ul>
<p>这便决定了无法一步到位升到 v1.28.x，而只能采用先升级到 v1.21.x 再逐步往上升级的方式。本文记录 v1.14.5 到 v1.21.14 的操作步骤和问题解决方式。</p>
<p>集群升级方式一般有两种，其一是另建目标集群并逐步迁移完所有服务，其二是逐节点原地升级。
如果选择另建 v1.21.x 并执行迁移的方式，先要在外层网关层实现集群切流功能，再要提前在新集群部署好所有服务，最终逐步完成切流。
考虑到我们没有主从集群切流层、机器资源相对有限、加之集群有状态服务没法简单挪移，因此选择了原地升级。</p>
<p>kubeadm 在 v1.29 之前仅支持逐 minor 版本升级集群，即只能 v1.14 -&gt; v1.15 -&gt; v1.16 -&gt; v1.17 -&gt; v1.18 -&gt; v1.19 -&gt; v1.20 -&gt; v1.21。详细可参考 <a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">Upgrading kubeadm clusters</a>。（kubeadm v1.29 之后将支持跨 3 个 minor 版本升级，即可以 v1.26 -&gt; v1.29 -&gt; v1.32，详细可参考 <a href="https://github.com/kubernetes/kubeadm/issues/2924">kubeadm#2924 - adjust the kubeadm/kubelet skew policy</a> 🚀</p>
<p>又，从 v1.14 至 v1.21，kubelet 与 apiserver 之间的通信 API 没有发生移除，v1.14 kubelet 可与 v1.14.5 到 v1.21.14 之间的任何版本的 apiserver 通信。
因此升级策略为</p>
<ol>
<li>逐步升级 control plane 至 v1.21</li>
<li>一步到位升级 worker node v1.14 至 v1.21</li>
</ol>
<img src="/img/2023/k8s-upgrade-flow.png" width="600px"/>
<p>这样做的好处是，即使升级 kubelet 时 Pod Containers 有被重启的风险。这事也只会发生一次。注意</p>
<ul>
<li>升级 kubelet 可能导致 Pod Containers 被重启，见 <a href="https://github.com/kubernetes/kubernetes/issues/63814">kubernetes#63814 - kubelet&rsquo;s calculation of whether a container has changed can cause cluster-wide outages</a></li>
<li>甚至升级 containerd 也可能导致重启 <a href="https://github.com/containerd/containerd/pull/7845">containerd#7845 - CRI: Fix no CNI info for pod sandbox on restart</a></li>
</ul>
<p>通常来说，健壮的服务群应能容忍偶发重启或者重新调度。</p>
<h2 id="cluster-级升级在首个-master-节点执行">cluster 级升级（在首个 master 节点执行</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="o">{</span>
</span></span><span class="line"><span class="cl"><span class="c1"># download kubeadm, kubelet, kubectl binary</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> VERSION in v1.15.12 v1.16.15 v1.17.17 v1.18.20 v1.19.16 v1.20.15 v1.21.14<span class="p">;</span> <span class="k">do</span>
</span></span><span class="line"><span class="cl">  wget -O /etc/kubernetes/upgrade/kubeadm-<span class="nv">$VERSION</span> https://storage.googleapis.com/kubernetes-release/release/<span class="nv">$VERSION</span>/bin/linux/amd64/kubeadm
</span></span><span class="line"><span class="cl">  chmod +x /etc/kubernetes/upgrade/kubeadm-<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">  wget -O /etc/kubernetes/upgrade/kubelet-<span class="nv">$VERSION</span> https://storage.googleapis.com/kubernetes-release/release/<span class="nv">$VERSION</span>/bin/linux/amd64/kubelet
</span></span><span class="line"><span class="cl">  chmod +x /etc/kubernetes/upgrade/kubelet-<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">  wget -O kubectl-<span class="nv">$VERSION</span> https://storage.googleapis.com/kubernetes-release/release/<span class="nv">$VERSION</span>/bin/linux/amd64/kubectl
</span></span><span class="line"><span class="cl">  chmod +x /etc/kubernetes/upgrade/kubectl-<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl"><span class="k">done</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># start copying container images to the private registry:  </span>
</span></span><span class="line"><span class="cl"><span class="c1">#   kube-apiserver, kube-controller-manager, kube-scheduler, kube-proxy, coredns, pause</span>
</span></span><span class="line"><span class="cl"><span class="c1"># if your company has no private registry, you can skip this step</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> VERSION in v1.15.12 v1.16.15 v1.17.17 v1.18.20 v1.19.16 v1.20.15 v1.21.14<span class="p">;</span> <span class="k">do</span>
</span></span><span class="line"><span class="cl">  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/kube-apiserver:<span class="nv">$VERSION</span> docker://myregisty/google-containers/kube-apiserver:<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/kube-controller-manager:<span class="nv">$VERSION</span> docker://myregisty/google-containers/kube-controller-manager:<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/kube-scheduler:<span class="nv">$VERSION</span> docker://myregisty/google-containers/kube-scheduler:<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/kube-proxy:<span class="nv">$VERSION</span> docker://myregisty/google-containers/kube-proxy:<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl"><span class="k">done</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> VERSION in 1.6.2 1.6.5 1.6.7 1.7.0 v1.8.0<span class="p">;</span> <span class="k">do</span>
</span></span><span class="line"><span class="cl">  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/coredns:<span class="nv">$VERSION</span> docker://myregistry/google-containers/coredns:<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl"><span class="k">done</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> VERSION in 3.2 3.4.1<span class="p">;</span> <span class="k">do</span>
</span></span><span class="line"><span class="cl">  skopeo copy --multi-arch all docker://registry.aliyuncs.com/google_containers/pause:<span class="nv">$VERSION</span> docker://myregistry/google-containers/pause:<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl"><span class="k">done</span>
</span></span><span class="line"><span class="cl"><span class="c1"># end copying container images</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>使用 <code>kubeadm upgrade apply &lt;targetVersion&gt;</code> 执行首个 control plane 升级。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># control plane 为 v1.14.5，woker nodes 为 v1.14.5，正常使用 kubeadm upgrade apply 即可</span>
</span></span><span class="line"><span class="cl">/etc/kubernetes/upgrade/kubeadm-v1.15.12 upgrade apply v1.15.12
</span></span><span class="line"><span class="cl"><span class="c1"># control plane 为 v1.15.12，woker nodes 为 v1.14.5，必须搭配 -f 参数强制升级</span>
</span></span><span class="line"><span class="cl">/etc/kubernetes/upgrade/kubeadm-v1.16.15 upgrade apply v1.16.15 -f
</span></span><span class="line"><span class="cl"><span class="c1"># control plane 为 v1.16.15，woker nodes 为 v1.14.5，必须搭配 -f 参数强制升级</span>
</span></span><span class="line"><span class="cl">/etc/kubernetes/upgrade/kubeadm-v1.17.17 upgrade apply v1.17.17 -f 
</span></span><span class="line"><span class="cl"><span class="c1"># control plane 为 v1.17.17，woker nodes 为 v1.14.5，必须搭配 -f 参数强制升级</span>
</span></span><span class="line"><span class="cl">/etc/kubernetes/upgrade/kubeadm-v1.18.20 upgrade apply v1.18.20 -f
</span></span><span class="line"><span class="cl"><span class="c1"># control plane 为 v1.18.20，woker nodes 为 v1.14.5，必须搭配 -f 参数强制升级</span>
</span></span><span class="line"><span class="cl">/etc/kubernetes/upgrade/kubeadm-v1.19.16 upgrade apply v1.19.16 -f
</span></span><span class="line"><span class="cl"><span class="c1"># control plane 为 v1.19.16，woker nodes 为 v1.14.5，必须搭配 -f 参数强制升级</span>
</span></span><span class="line"><span class="cl">/etc/kubernetes/upgrade/kubeadm-v1.20.15 upgrade apply v1.20.15 -f
</span></span><span class="line"><span class="cl"><span class="c1"># control plane 为 v1.20.15，woker nodes 为 v1.14.5，必须搭配 -f 参数强制升级</span>
</span></span><span class="line"><span class="cl">/etc/kubernetes/upgrade/kubeadm-v1.21.14 upgrade apply v1.21.14 -f
</span></span></code></pre></td></tr></table>
</div>
</div><p>每次执行之后，大致发生以下事情</p>
<ul>
<li>apply kube-system 中的集群配置，如 kubeadm-config (i.e ClusterConfiguration)，kubelet-config-$VERSION，CoreDNS 以及 kube-proxy ConfigMap</li>
<li>更新首个 master 节点上的 kube-apiserver, kube-controller-manager, kube-scheduler（即 /etc/kubernetes/manifests 目录的 static Pod manifests</li>
<li>更新集群中的 CoreDNS 和 kube-proxy</li>
</ul>
<p>所以每次更新完集群之后，需要检查以下服务是否正常运行</p>
<ul>
<li>首个 master 节点上的 kube-apiserver, kube-controller-manager, kube-scheduler</li>
<li>CoreDNS</li>
<li>kube-proxy</li>
<li>CNI Plugin</li>
</ul>
<h2 id="其他-master-节点更新">其他 master 节点更新</h2>
<p>下载程序</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="o">{</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> VERSION in v1.15.12 v1.16.15 v1.17.17 v1.18.20 v1.19.16 v1.20.15 v1.21.14<span class="p">;</span> <span class="k">do</span>
</span></span><span class="line"><span class="cl">  wget -O /etc/kubernetes/upgrade/kubeadm-<span class="nv">$VERSION</span> https://storage.googleapis.com/kubernetes-release/release/<span class="nv">$VERSION</span>/bin/linux/amd64/kubeadm
</span></span><span class="line"><span class="cl">  chmod +x /etc/kubernetes/upgrade/kubeadm-<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">  wget -O /etc/kubernetes/upgrade/kubelet-<span class="nv">$VERSION</span> https://storage.googleapis.com/kubernetes-release/release/<span class="nv">$VERSION</span>/bin/linux/amd64/kubelet
</span></span><span class="line"><span class="cl">  chmod +x /etc/kubernetes/upgrade/kubelet-<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">  wget -O kubectl-<span class="nv">$VERSION</span> https://storage.googleapis.com/kubernetes-release/release/<span class="nv">$VERSION</span>/bin/linux/amd64/kubectl
</span></span><span class="line"><span class="cl">  chmod +x /etc/kubernetes/upgrade/kubectl-<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl"><span class="k">done</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>执行 <code>kubeadm upgrade node</code> 即可</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="o">{</span> 
</span></span><span class="line"><span class="cl"><span class="nv">VERSION</span><span class="o">=</span>v1.15.12 <span class="c1"># v1.16.15 ... v1.21.14 等其他版本对号入座</span>
</span></span><span class="line"><span class="cl">./kubeadm-<span class="nv">$VERSION</span> upgrade node --certificate-renewal<span class="o">=</span><span class="nb">false</span>
</span></span><span class="line"><span class="cl">mv kubelet-<span class="nv">$VERSION</span> /usr/local/bin/kubelet
</span></span><span class="line"><span class="cl">sudo systemctl daemon-reload
</span></span><span class="line"><span class="cl">sudo systemctl restart kubelet
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>对于 control plane 所在节点，执行 <code>kubeadm upgrade node</code> 会</p>
<ul>
<li>获取 kubeadm <code>ClusterConfiguration</code>，更新 kube-apiserver, kube-controller-manager, kube-scheduler （即 static Pod manifests</li>
<li>更新 kubelet 启动配置</li>
</ul>
<p>因此之后只要更换 kubelet 二进制，重启 kubelet 即可完成 control plane 节点更新。</p>
<h2 id="114--115-踩坑记录">1.14 → 1.15 踩坑记录</h2>
<ul>
<li>
<p>kubelet 无法启动，原因是 <a href="https://github.com/kubernetes/kubernetes/pull/77820">kubernetes#77820 - Remove deprecated Kubelet security controls</a> 移除了该参数</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Nov 28 18:05:27 master-1 kubelet[884]: F1128 18:05:27.064279     884 server.go:156] unknown flag: --allow-privileged
</span></span></code></pre></td></tr></table>
</div>
</div><p>解决方式，在 /etc/kubernetes/kubelet.env 移除 <code>KUBE_ALLOW_PRIV=&quot;--allow-privileged=true&quot;</code> 并在  /etc/systemd/system/kubelet.service 移除 <code>$KUBE_ALLOW_PRIV</code> 环境变量引用。</p>
</li>
<li>
<p>coredns deployments 新 Pod 无法被创建，原因是 kube-system 中有莫名其妙的 LimitRange 资源，限制了容器最小资源请求最小 CPU 为 100m，最小 Memory 为 100Mi。解决方式，删除 LimitRange 即可。</p>
</li>
<li>
<p>自研 AutoScaler 组件失效，使用 label container_name 突然取不到 CPU Metrics 数据。原因是 1.15 后 <a href="https://github.com/kubernetes/kubernetes/pull/76074">kubernetes#76074 - change kubelet probe metrics to counter</a> 移除了 CPU Metrics label container_name。解决方式是修改 Metrics 查询为 label container。如果使用了 label pod_name，也应该修改为 label pod。</p>
</li>
</ul>
<h2 id="115---116-踩坑记录">1.15 -&gt; 1.16 踩坑记录</h2>
<p>更新镜像到 <code>coredns:1.6.2</code> 之后，CoreDNS Deployment 下的 Pod 正常 Running 但一直未 Ready。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">root@master-0:/etc/kubernetes/upgrade# kubectl -n kube-system get po <span class="p">|</span> grep core
</span></span><span class="line"><span class="cl">coredns-8656b5f45f-gvbqd                  1/1     Running   <span class="m">1</span>          20h
</span></span><span class="line"><span class="cl">coredns-ddd4d886f-4nwd5                   0/1     Running   <span class="m">0</span>          24m
</span></span><span class="line"><span class="cl">coredns-ddd4d886f-nk9mp                   0/1     Running   <span class="m">0</span>          24m
</span></span></code></pre></td></tr></table>
</div>
</div><p>原因是 coreDNS 1.6 之后 readiness serve 改为了插件模式，详见 <a href="https://github.com/coredns/coredns/issues/3219">coredns#3219 - Readiness probe failed 8181: connect: connection refused</a></p>
<p>解决方式：<code>kubectl -n kube-system edit cm coredns</code> 激活 ready 插件</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ConfigMap</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">coredns</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kube-system</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">data</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">Corefile</span><span class="p">:</span><span class="w"> </span><span class="p">|</span><span class="sd">
</span></span></span><span class="line"><span class="cl"><span class="sd">    .:53 {
</span></span></span><span class="line"><span class="cl"><span class="sd">        errors
</span></span></span><span class="line"><span class="cl"><span class="sd">        health {
</span></span></span><span class="line"><span class="cl"><span class="sd">            lameduck 5s
</span></span></span><span class="line"><span class="cl"><span class="sd">        }
</span></span></span><span class="line"><span class="cl"><span class="sd">        kubernetes lac-k8s-prd.local in-addr.arpa ip6.arpa {
</span></span></span><span class="line"><span class="cl"><span class="sd">            pods insecure
</span></span></span><span class="line"><span class="cl"><span class="sd">            fallthrough in-addr.arpa ip6.arpa
</span></span></span><span class="line"><span class="cl"><span class="sd">        }
</span></span></span><span class="line"><span class="cl"><span class="sd">        prometheus :9153
</span></span></span><span class="line"><span class="cl"><span class="sd">        ready :8181 # 增加这一行
</span></span></span><span class="line"><span class="cl"><span class="sd">        forward . /etc/resolv.conf {
</span></span></span><span class="line"><span class="cl"><span class="sd">            max_concurrent 1000
</span></span></span><span class="line"><span class="cl"><span class="sd">        }
</span></span></span><span class="line"><span class="cl"><span class="sd">        cache 30
</span></span></span><span class="line"><span class="cl"><span class="sd">        loop
</span></span></span><span class="line"><span class="cl"><span class="sd">        reload
</span></span></span><span class="line"><span class="cl"><span class="sd">        loadbalance
</span></span></span><span class="line"><span class="cl"><span class="sd">    }</span><span class="w">    
</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="118---119-踩坑记录">1.18 -&gt; 1.19 踩坑记录</h2>
<ul>
<li>feature gate <code>VolumeSubpathEnvExpansion</code> 在 1.19 被移除，导致执行 <code>kubeadm upgrade</code> 后，kube-apiserver, kube-controller-manager, kube-scheduler, kube-proxy, kubelet 均无法启动。解决方式
<ol>
<li>提前自 kubeadm ClusterConfiguration 中移除 <code>feature-gates: VolumeSubpathEnvExpansion=true</code>。一般是置空 <code>- --feature-gates=</code>。</li>
<li>提前自 kube-proxy ConfigMap 移除 <code>feature-gates: VolumeSubpathEnvExpansion=true</code>。</li>
<li>提前自 /etc/kubernetes/kubelet.env 移除 <code>feature-gates: VolumeSubpathEnvExpansion=true</code>。（<code>sed -i '/--feature-gates=VolumeSubpathEnvExpansion=true \\/d'  /etc/kubernetes/kubelet.env</code></li>
</ol>
</li>
<li>触发 Prometheus 告警: 😱🚀 KubeScheduler/KubeControllerManager has disappeared from Prometheus target discovery。
原因是 Prometheus 使用 HTTP EndPoints <host>:10251/ready 探测 KubeScheduler 是否就绪，但在 1.19 移除了这一默认端口。
详见 <a href="https://github.com/kubernetes/kubeadm/issues/2207">kubeadm#2207 - remove &ndash;port from kube-controller-manager and kube-scheduler</a>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">up{endpoint=&#34;http-metrics&#34;,instance=&#34;10.40.34.34:10251&#34;,job=&#34;kube-scheduler&#34;,namespace=&#34;kube-system&#34;,pod=&#34;kube-scheduler-master0&#34;,service=&#34;basic-kube-scheduler&#34;} 
</span></span><span class="line"><span class="cl">0
</span></span></code></pre></td></tr></table>
</div>
</div>解决方式，自己 kube-scheduler 和 kube-controller-manager manifest 删除启动参数 <code>- --port=0</code>（<code>sed -i '/- --port=0/d'  /etc/kubernetes/manifests/kube-scheduler.yaml  /etc/kubernetes/manifests/kube-controller-manager.yaml</code></li>
<li>部分 Webhook 证书突然失效
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">2023-11-30T14:46:44.577+0800    ERROR ... 
</span></span><span class="line"><span class="cl">err: Internal error occurred: 
</span></span><span class="line"><span class="cl">failed calling webhook \&#34;mutate-deploy.x.com\&#34;: 
</span></span><span class="line"><span class="cl">  Post \&#34;https://x.kube-system.svc:443/mutate-deployment?timeout=30s\&#34;: 
</span></span><span class="line"><span class="cl">    x509: certificate relies on legacy Common Name field, 
</span></span><span class="line"><span class="cl">      use SANs or temporarily enable Common Name matching with GODEBUG=x509ignoreCN=0&#34;
</span></span></code></pre></td></tr></table>
</div>
</div>解决方式，更新 kube-apiserver manifests，给 Pod 增加环境变量即可
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">env:
</span></span><span class="line"><span class="cl">- name: GODEBUG
</span></span><span class="line"><span class="cl">value: &#34;x509ignoreCN=0&#34;
</span></span></code></pre></td></tr></table>
</div>
</div>该方式在 1.23 前有效，详见 <a href="https://cloud.google.com/kubernetes-engine/docs/deprecations/webhookcompatibility">GKE: Ensuring compatibility of webhook certificates before upgrading to v1.23</a></li>
</ul>
<h2 id="119---120-注意点">1.19 -&gt; 1.20 注意点</h2>
<ul>
<li>kubelet 会使用 pause:3.2，需要保证 pause:3.2 在内网可拉取</li>
<li>v1.19 至 v1.20 最大变化就是废弃了 <code>apiserver serve on an insecure port</code>，因此在升级前应该修改 kubeadm ClusterConfiguration 移除 apiserver 参数 <code>--insecure-bind-address</code> 和参数 <code>--insecure-port</code>。同时应该检查左右客户端 kubeconfig，如果使用了 HTTP 连接 kube-apiserver，应该更新至 HTTPS 版。</li>
<li>为兼容 Prometheus HTTP 探测 kube-scheduler 和 kube-controller-manager，应该继续执行 <code>sed -i '/- --port=0/d'  /etc/kubernetes/manifests/kube-scheduler.yaml  /etc/kubernetes/manifests/kube-controller-manager.yaml</code></li>
<li>1.20 kubelet 移除了 endpoint <code>metrics/resource/v1alpha1</code>，如果 Prometheus 配置了从该路径爬取 Metrics 的 ServiceMonitor，需修改对应资源，改成 <code>metrics/resource</code></li>
</ul>
<h2 id="120---121-注意点">1.20 -&gt; 1.21 注意点</h2>
<ul>
<li>kubelet 会使用 pause:3.4.1，需要保证 pause:3.4.1 在内网可拉取</li>
<li>为兼容 Prometheus HTTP 探测 kube-scheduler 和 kube-controller-manager，应该继续执行 <code>sed -i '/- --port=0/d'  /etc/kubernetes/manifests/kube-scheduler.yaml  /etc/kubernetes/manifests/kube-controller-manager.yaml</code></li>
<li>1.21 feature BoundServiceAccountTokenVolume 默认启用后，ServiceAccount 凭证从 Secret 挂载改为动态 Token 获取。按照声明来看挂载权限无差异。但在生产集群中，Pod Container 设置 <code>securityContext.runAsUser: 101</code> 以非 root user 运行时，读取 token 文件报错 <code>open /var/run/secrets/kubernetes.io/serviceaccount/token: permission denied</code> (container image: quay.io/kubernetes-ingress-controller/<a href="https://github.com/kubernetes/ingress-nginx/tree/controller-0.31.0">nginx-ingress-controller:0.31.0</a>)。
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl"># before 1.21
</span></span><span class="line"><span class="cl">- name: nginx-ingress-serviceaccount-token-vqxzw
</span></span><span class="line"><span class="cl">  secret:
</span></span><span class="line"><span class="cl">    defaultMode: 420
</span></span><span class="line"><span class="cl">    secretName: nginx-ingress-serviceaccount-token-vqxzw
</span></span><span class="line"><span class="cl">---
</span></span><span class="line"><span class="cl"># after 1.21
</span></span><span class="line"><span class="cl">volumes:
</span></span><span class="line"><span class="cl">- name: kube-api-access-xbwws
</span></span><span class="line"><span class="cl">  projected:
</span></span><span class="line"><span class="cl">    defaultMode: 420
</span></span><span class="line"><span class="cl">    sources:
</span></span><span class="line"><span class="cl">    - serviceAccountToken:
</span></span><span class="line"><span class="cl">        expirationSeconds: 3607
</span></span><span class="line"><span class="cl">        path: token
</span></span><span class="line"><span class="cl">    - configMap:
</span></span><span class="line"><span class="cl">        items:
</span></span><span class="line"><span class="cl">        - key: ca.crt
</span></span><span class="line"><span class="cl">          path: ca.crt
</span></span><span class="line"><span class="cl">        name: kube-root-ca.crt
</span></span><span class="line"><span class="cl">    - downwardAPI:
</span></span><span class="line"><span class="cl">      items:
</span></span><span class="line"><span class="cl">      - fieldRef:
</span></span><span class="line"><span class="cl">          apiVersion: v1
</span></span><span class="line"><span class="cl">          fieldPath: metadata.namespace
</span></span><span class="line"><span class="cl">        path: namespace
</span></span></code></pre></td></tr></table>
</div>
</div>解决方式：为 Pod 设置 <code>spec.securityContext.fsGroup: 65534</code>，确保所有 container 对挂载目录有读取权限。</li>
</ul>
<h2 id="系统级镜像坑点">系统级镜像坑点</h2>
<p>如因内网环境或者其他原因导致国外镜像不可达，应该使用 <code>kubeadm apply &lt;targetVersion&gt; --dry-run</code> 打印执行结果，重点 grep 如下组件镜像并提前做好分发</p>
<ul>
<li>CoreDNS</li>
<li>pause</li>
</ul>
<p>小节 cluster 级升级开头的镜像分发是走完整个流程的成果。</p>
<h2 id="任意-worker-节点更新">任意 worker 节点更新</h2>
<p>走完 control plane 节点更新，也就踩完了普通 worker 节点的坑。脚化处理即可。找一台可以登陆所有 worker 的机器，准备脚本 <code>upgrade-worker.sh</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="cp">#!/bin/bash
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="nv">VERSION</span><span class="o">=</span>v1.21.14
</span></span><span class="line"><span class="cl"><span class="nv">UPGRADEDIR</span><span class="o">=</span>/etc/kubernetes/upgrade
</span></span><span class="line"><span class="cl">mkdir -p <span class="nv">$UPGRADEDIR</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">wget -O <span class="nv">$UPGRADEDIR</span>/kubeadm-<span class="nv">$VERSION</span> https://storage.googleapis.com/kubernetes-release/release/<span class="nv">$VERSION</span>/bin/linux/amd64/kubeadm
</span></span><span class="line"><span class="cl">chmod +x <span class="nv">$UPGRADEDIR</span>/kubeadm-<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">wget -O <span class="nv">$UPGRADEDIR</span>/kubelet-<span class="nv">$VERSION</span> https://storage.googleapis.com/kubernetes-release/release/<span class="nv">$VERSION</span>/bin/linux/amd64/kubelet
</span></span><span class="line"><span class="cl">chmod +x <span class="nv">$UPGRADEDIR</span>/kubelet-<span class="nv">$VERSION</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># start of updating args, it depends on your kubelet&#39;s status, don&#39;t use it</span>
</span></span><span class="line"><span class="cl">sed -i <span class="s1">&#39;/# Should this cluster be allowed to run privileged docker containers/d; /KUBE_ALLOW_PRIV=&#34;--allow-privileged=true&#34;/d&#39;</span> /etc/kubernetes/kubelet.env
</span></span><span class="line"><span class="cl">sed -i <span class="s1">&#39;/\$KUBE_ALLOW_PRIV \\/d&#39;</span> /etc/systemd/system/kubelet.service
</span></span><span class="line"><span class="cl">sed -i <span class="s1">&#39;/--feature-gates=VolumeSubpathEnvExpansion=true \\/d&#39;</span>  /etc/kubernetes/kubelet.env
</span></span><span class="line"><span class="cl">sed -i <span class="s1">&#39;s|google-containers/pause-amd64:3.1|google-containers/pause:3.4.1|&#39;</span> /etc/kubernetes/kubelet.env
</span></span><span class="line"><span class="cl"><span class="c1"># end of updating args, it depends on your kubelet&#39;s status, don&#39;t use it</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">$UPGRADEDIR</span>/kubeadm-<span class="nv">$VERSION</span> upgrade node
</span></span><span class="line"><span class="cl">mv <span class="nv">$UPGRADEDIR</span>/kubelet-<span class="nv">$VERSION</span> /usr/local/bin/kubelet
</span></span><span class="line"><span class="cl">systemctl daemon-reload
</span></span><span class="line"><span class="cl">systemctl restart kubelet
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后按照实际业务情况，分批次完成 kubelet v1.14 至 v1.21 升级。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="k">for</span> NODE in work-1 work-2 work-3<span class="p">;</span> <span class="k">do</span>
</span></span><span class="line"><span class="cl">    kubectl drain <span class="nv">$NODE</span> --ignore-daemonsets --delete-local-data
</span></span><span class="line"><span class="cl">    ssh <span class="nv">$NODE</span> <span class="s2">&#34;bash -s&#34;</span> -- &lt; /etc/kubernetes/upgrade/upgrade-worker.sh
</span></span><span class="line"><span class="cl">    kubectl uncordon <span class="nv">$NODE</span>
</span></span><span class="line"><span class="cl"><span class="k">done</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>注意: kubelet 更新时的参数更新，如 <code>参数移除</code>， <code>feature-gates 移除</code>， <code>pause container 更新</code> 等，具体因实际集群而异。</p>
<h2 id="总结">总结</h2>
<p>集群升级概要</p>
<ol>
<li>先测试集群后生产集群，先小集群后大集群</li>
<li>提前备份 etcd，虽然本文没用上备份 👻</li>
<li>查阅 <a href="https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG">Kubernetes CHANGELOG</a>，注意新版本核心组件的参数移除，尤其是 feature gates 移除会涉及所有 <code>kube-</code> 打头组件</li>
<li>提前 <code>kubeadm upgrade &lt;version&gt; --dryrun</code> 检查新版本镜像，做好 CoreDNS 和 puase 容器镜像分发</li>
<li>upgrade 完成后，检查 CoreDNS 和 kube-proxy 所有 Pod 状态，确保更新完成；检查集群 DNS 功能是否正常；检查集群 Service 功能是否正常</li>
<li>每次 upgrade 完成，检查 Operator/Controller 和关键业务应用是否正常（关注日志/监控/告警），检查核心 API CRUD 是否正常（防止 Webhook 崩坏）</li>
</ol>
<p>Container Runtime 更新部分、最终操作方式和脚本请查阅 <a href="../2024-kubernetes-upgrade-lessons">Kubernetes v1.14.5 → v1.21.14 升级补遗及经验教训</a>。</p>
<h2 id="参考链接">参考链接</h2>
<ul>
<li>TauCeti.blog&rsquo;s Kubernetes upgrade notes: <a href="https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.14-1.15/">1.14-1.15</a>, <a href="https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.15-1.16/">1.15-1.16</a>, <a href="https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.16-1.17/">1.16-1.17</a>, <a href="https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.17-1.18/">1.17-1.18</a>, <a href="https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.17-1.18/">1.18-1.19</a>, <a href="https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.17-1.18/">1.19-1.20</a>, <a href="https://www.tauceti.blog/posts/kubernetes-upgrade-nodes-1.20-1.21/">1.20-1.21</a></li>
<li><a href="https://kubernetes.io/docs/reference/using-api/deprecation-guide">Deprecated API Migration Guide</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">Upgrading kubeadm clusters</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG">Kubernetes CHANGELOG</a></li>
</ul>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Zeng Xu</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2024-05-24 16:38
        
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content">本作品采用 <a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a> 进行许可，转载时请注明原文链接。</span>
  </p>
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kubernetes/">kubernetes</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/2023-retriable-http-client/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Notes on Retriable HTTP Client (with Golang/Rust example</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/2023-kubevirt-mix-kubeovn-calico/">
            <span class="next-text nav-default">Calico ➕ KubeOVN —— 为 KubeVirt VMs 提供受限的 underlay 网络访问</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js" crossorigin="anonymous"></script>
    <script type="text/javascript">
      var gitalk = new Gitalk({
        id: '2023-11-30 16:58:24 \u002b0800 CST',
        title: 'v1.14.5 - v1.21.14 Kubernetes 跨版本升级记录',
        clientID: '6ab3c721bb197ea92f1e',
        clientSecret: '217d38cc1905f60f1d963c555be606ed3e707937',
        repo: 'phosae.github.io',
        owner: 'phosae',
        admin: ['phosae'],
        body: decodeURI(location.href)
      });
      gitalk.render('gitalk-container');
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/gitalk/gitalk">comments powered by gitalk.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:zenngxu@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/phosae" class="iconfont icon-github" title="github"></a>
      <a href="https://weibo.com/u/1566013967" class="iconfont icon-weibo" title="weibo"></a>
  <a href="https://www.zeng.dev/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2019 - 
    2024<span class="heart"><i class="iconfont icon-heart"></i></span><span>Zeng Xu</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEPN2KZF84"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FEPN2KZF84');
        }
      </script>
    
  











</body>
</html>
